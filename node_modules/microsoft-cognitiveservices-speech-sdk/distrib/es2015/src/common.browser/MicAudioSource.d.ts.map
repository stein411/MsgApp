{"version":3,"sources":["src/common.browser/MicAudioSource.ts"],"names":[],"mappings":"AAGA,OAAO,EACH,iBAAiB,EAEpB,MAAM,uCAAuC,CAAC;AAC/C,OAAO,EAEH,wBAAwB,EAE3B,MAAM,0BAA0B,CAAC;AAClC,OAAO,EAEH,gBAAgB,EAYhB,WAAW,EACX,YAAY,EACZ,gBAAgB,EAEhB,OAAO,EAIV,MAAM,mBAAmB,CAAC;AAC3B,OAAO,EAAE,SAAS,EAAE,MAAM,aAAa,CAAC;AASxC,eAAO,MAAM,iCAAiC,gCAAgC,CAAC;AAE/E,qBAAa,cAAe,YAAW,YAAY;IAqB3C,OAAO,CAAC,QAAQ,CAAC,YAAY;IAG7B,OAAO,CAAC,QAAQ,CAAC,QAAQ,CAAC;IAtB9B,OAAO,CAAC,MAAM,CAAC,QAAQ,CAAC,WAAW,CAA6F;IAEhI,OAAO,CAAC,WAAW,CAA8C;IAEjE,OAAO,CAAC,MAAM,CAAS;IAEvB,OAAO,CAAC,UAAU,CAAgC;IAElD,OAAO,CAAC,sBAAsB,CAAoB;IAElD,OAAO,CAAC,eAAe,CAAc;IAErC,OAAO,CAAC,WAAW,CAAe;IAElC,OAAO,CAAC,mBAAmB,CAAS;IAEpC,OAAO,CAAC,mBAAmB,CAAS;gBAGf,YAAY,EAAE,SAAS,EACxC,eAAe,EAAE,MAAM,EACvB,aAAa,CAAC,EAAE,MAAM,EACL,QAAQ,CAAC,EAAE,MAAM;aAO3B,MAAM,EAAI,iBAAiB;IAI/B,MAAM,yBAmEZ;IAEM,EAAE,eAER;IAEM,MAAM,qDAqBZ;IAEM,MAAM,gCAMZ;IAEM,OAAO,yBAgBb;aAEU,MAAM,EAAI,WAAW,CAAC,gBAAgB,CAAC;aAIvC,UAAU,EAAI,OAAO,CAAC,wBAAwB,CAAC;IAcnD,WAAW,CAAC,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,MAAM,GAAG,IAAI;IAQrD,OAAO,CAAC,kBAAkB;IAyC1B,OAAO,CAAC,MAAM,CAeb;IAED,OAAO,CAAC,OAAO,CAGd;IAED,OAAO,CAAC,kBAAkB,CAezB;IAED,OAAO,CAAC,mBAAmB,CA2B1B;CACJ","file":"MicAudioSource.d.ts","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport {\r\n    AudioStreamFormat,\r\n    AudioStreamFormatImpl,\r\n} from \"../../src/sdk/Audio/AudioStreamFormat\";\r\nimport {\r\n    connectivity,\r\n    ISpeechConfigAudioDevice,\r\n    type\r\n} from \"../common.speech/Exports\";\r\nimport {\r\n    AudioSourceErrorEvent,\r\n    AudioSourceEvent,\r\n    AudioSourceInitializingEvent,\r\n    AudioSourceOffEvent,\r\n    AudioSourceReadyEvent,\r\n    AudioStreamNodeAttachedEvent,\r\n    AudioStreamNodeAttachingEvent,\r\n    AudioStreamNodeDetachedEvent,\r\n    AudioStreamNodeErrorEvent,\r\n    ChunkedArrayBufferStream,\r\n    createNoDashGuid,\r\n    Deferred,\r\n    Events,\r\n    EventSource,\r\n    IAudioSource,\r\n    IAudioStreamNode,\r\n    IStringDictionary,\r\n    Promise,\r\n    PromiseHelper,\r\n    Stream,\r\n    StreamReader,\r\n} from \"../common/Exports\";\r\nimport { IRecorder } from \"./IRecorder\";\r\n\r\n// Extending the default definition with browser specific definitions for backward compatibility\r\ninterface INavigatorUserMedia extends NavigatorUserMedia {\r\n    webkitGetUserMedia?: (constraints: MediaStreamConstraints, successCallback: NavigatorUserMediaSuccessCallback, errorCallback: NavigatorUserMediaErrorCallback) => void;\r\n    mozGetUserMedia?: (constraints: MediaStreamConstraints, successCallback: NavigatorUserMediaSuccessCallback, errorCallback: NavigatorUserMediaErrorCallback) => void;\r\n    msGetUserMedia?: (constraints: MediaStreamConstraints, successCallback: NavigatorUserMediaSuccessCallback, errorCallback: NavigatorUserMediaErrorCallback) => void;\r\n}\r\n\r\nexport const AudioWorkletSourceURLPropertyName = \"MICROPHONE-WorkletSourceUrl\";\r\n\r\nexport class MicAudioSource implements IAudioSource {\r\n\r\n    private static readonly AUDIOFORMAT: AudioStreamFormatImpl = AudioStreamFormat.getDefaultInputFormat() as AudioStreamFormatImpl;\r\n\r\n    private privStreams: IStringDictionary<Stream<ArrayBuffer>> = {};\r\n\r\n    private privId: string;\r\n\r\n    private privEvents: EventSource<AudioSourceEvent>;\r\n\r\n    private privInitializeDeferral: Deferred<boolean>;\r\n\r\n    private privMediaStream: MediaStream;\r\n\r\n    private privContext: AudioContext;\r\n\r\n    private privMicrophoneLabel: string;\r\n\r\n    private privOutputChunkSize: number;\r\n\r\n    public constructor(\r\n        private readonly privRecorder: IRecorder,\r\n        outputChunkSize: number,\r\n        audioSourceId?: string,\r\n        private readonly deviceId?: string) {\r\n\r\n        this.privOutputChunkSize = outputChunkSize;\r\n        this.privId = audioSourceId ? audioSourceId : createNoDashGuid();\r\n        this.privEvents = new EventSource<AudioSourceEvent>();\r\n    }\r\n\r\n    public get format(): AudioStreamFormat {\r\n        return MicAudioSource.AUDIOFORMAT;\r\n    }\r\n\r\n    public turnOn = (): Promise<boolean> => {\r\n        if (this.privInitializeDeferral) {\r\n            return this.privInitializeDeferral.promise();\r\n        }\r\n\r\n        this.privInitializeDeferral = new Deferred<boolean>();\r\n\r\n        this.createAudioContext();\r\n\r\n        const nav = window.navigator as INavigatorUserMedia;\r\n\r\n        let getUserMedia = (\r\n            nav.getUserMedia ||\r\n            nav.webkitGetUserMedia ||\r\n            nav.mozGetUserMedia ||\r\n            nav.msGetUserMedia\r\n        );\r\n\r\n        if (!!nav.mediaDevices) {\r\n            getUserMedia = (constraints: MediaStreamConstraints, successCallback: NavigatorUserMediaSuccessCallback, errorCallback: NavigatorUserMediaErrorCallback): void => {\r\n                nav.mediaDevices\r\n                    .getUserMedia(constraints)\r\n                    .then(successCallback)\r\n                    .catch(errorCallback);\r\n            };\r\n        }\r\n\r\n        if (!getUserMedia) {\r\n            const errorMsg = \"Browser does not support getUserMedia.\";\r\n            this.privInitializeDeferral.reject(errorMsg);\r\n            this.onEvent(new AudioSourceErrorEvent(errorMsg, \"\")); // mic initialized error - no streamid at this point\r\n        } else {\r\n            const next = () => {\r\n                this.onEvent(new AudioSourceInitializingEvent(this.privId)); // no stream id\r\n                getUserMedia(\r\n                    { audio: this.deviceId ? { deviceId: this.deviceId } : true, video: false },\r\n                    (mediaStream: MediaStream) => {\r\n                        this.privMediaStream = mediaStream;\r\n                        this.onEvent(new AudioSourceReadyEvent(this.privId));\r\n                        this.privInitializeDeferral.resolve(true);\r\n                    }, (error: MediaStreamError) => {\r\n                        const errorMsg = `Error occurred during microphone initialization: ${error}`;\r\n                        const tmp = this.privInitializeDeferral;\r\n                        // HACK: this should be handled through onError callbacks of all promises up the stack.\r\n                        // Unfortunately, the current implementation does not provide an easy way to reject promises\r\n                        // without a lot of code replication.\r\n                        // TODO: fix promise implementation, allow for a graceful reject chaining.\r\n                        this.privInitializeDeferral = null;\r\n                        tmp.reject(errorMsg); // this will bubble up through the whole chain of promises,\r\n                        // with each new level adding extra \"Unhandled callback error\" prefix to the error message.\r\n                        // The following line is not guaranteed to be executed.\r\n                        this.onEvent(new AudioSourceErrorEvent(this.privId, errorMsg));\r\n                    });\r\n            };\r\n\r\n            if (this.privContext.state === \"suspended\") {\r\n                // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.\r\n                // https://github.com/WebAudio/web-audio-api/issues/790\r\n                this.privContext.resume().then(next, (reason: any) => {\r\n                    this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);\r\n                });\r\n            } else {\r\n                next();\r\n            }\r\n        }\r\n\r\n        return this.privInitializeDeferral.promise();\r\n    }\r\n\r\n    public id = (): string => {\r\n        return this.privId;\r\n    }\r\n\r\n    public attach = (audioNodeId: string): Promise<IAudioStreamNode> => {\r\n        this.onEvent(new AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\r\n\r\n        return this.listen(audioNodeId).onSuccessContinueWith<IAudioStreamNode>(\r\n            (streamReader: StreamReader<ArrayBuffer>) => {\r\n                this.onEvent(new AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\r\n                return {\r\n                    detach: () => {\r\n                        streamReader.close();\r\n                        delete this.privStreams[audioNodeId];\r\n                        this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\r\n                        this.turnOff();\r\n                    },\r\n                    id: () => {\r\n                        return audioNodeId;\r\n                    },\r\n                    read: () => {\r\n                        return streamReader.read();\r\n                    },\r\n                };\r\n            });\r\n    }\r\n\r\n    public detach = (audioNodeId: string): void => {\r\n        if (audioNodeId && this.privStreams[audioNodeId]) {\r\n            this.privStreams[audioNodeId].close();\r\n            delete this.privStreams[audioNodeId];\r\n            this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\r\n        }\r\n    }\r\n\r\n    public turnOff = (): Promise<boolean> => {\r\n        for (const streamId in this.privStreams) {\r\n            if (streamId) {\r\n                const stream = this.privStreams[streamId];\r\n                if (stream) {\r\n                    stream.close();\r\n                }\r\n            }\r\n        }\r\n\r\n        this.onEvent(new AudioSourceOffEvent(this.privId)); // no stream now\r\n        this.privInitializeDeferral = null;\r\n\r\n        this.destroyAudioContext();\r\n\r\n        return PromiseHelper.fromResult(true);\r\n    }\r\n\r\n    public get events(): EventSource<AudioSourceEvent> {\r\n        return this.privEvents;\r\n    }\r\n\r\n    public get deviceInfo(): Promise<ISpeechConfigAudioDevice> {\r\n        return this.getMicrophoneLabel().onSuccessContinueWith((label: string) => {\r\n            return {\r\n                bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,\r\n                channelcount: MicAudioSource.AUDIOFORMAT.channels,\r\n                connectivity: connectivity.Unknown,\r\n                manufacturer: \"Speech SDK\",\r\n                model: label,\r\n                samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,\r\n                type: type.Microphones,\r\n            };\r\n        });\r\n    }\r\n\r\n    public setProperty(name: string, value: string): void {\r\n        if (name === AudioWorkletSourceURLPropertyName) {\r\n            this.privRecorder.setWorkletUrl(value);\r\n        } else {\r\n            throw new Error(\"Property '\" + name + \"' is not supported on Microphone.\");\r\n        }\r\n    }\r\n\r\n    private getMicrophoneLabel(): Promise<string> {\r\n        const defaultMicrophoneName: string = \"microphone\";\r\n\r\n        // If we did this already, return the value.\r\n        if (this.privMicrophoneLabel !== undefined) {\r\n            return PromiseHelper.fromResult(this.privMicrophoneLabel);\r\n        }\r\n\r\n        // If the stream isn't currently running, we can't query devices because security.\r\n        if (this.privMediaStream === undefined || !this.privMediaStream.active) {\r\n            return PromiseHelper.fromResult(defaultMicrophoneName);\r\n        }\r\n\r\n        // Setup a default\r\n        this.privMicrophoneLabel = defaultMicrophoneName;\r\n\r\n        // Get the id of the device running the audio track.\r\n        const microphoneDeviceId: string = this.privMediaStream.getTracks()[0].getSettings().deviceId;\r\n\r\n        // If the browser doesn't support getting the device ID, set a default and return.\r\n        if (undefined === microphoneDeviceId) {\r\n            return PromiseHelper.fromResult(this.privMicrophoneLabel);\r\n        }\r\n\r\n        const deferred: Deferred<string> = new Deferred<string>();\r\n\r\n        // Enumerate the media devices.\r\n        navigator.mediaDevices.enumerateDevices().then((devices: MediaDeviceInfo[]) => {\r\n            for (const device of devices) {\r\n                if (device.deviceId === microphoneDeviceId) {\r\n                    // Found the device\r\n                    this.privMicrophoneLabel = device.label;\r\n                    break;\r\n                }\r\n            }\r\n            deferred.resolve(this.privMicrophoneLabel);\r\n        }, () => deferred.resolve(this.privMicrophoneLabel));\r\n\r\n        return deferred.promise();\r\n    }\r\n\r\n    private listen = (audioNodeId: string): Promise<StreamReader<ArrayBuffer>> => {\r\n        return this.turnOn()\r\n            .onSuccessContinueWith<StreamReader<ArrayBuffer>>((_: boolean) => {\r\n                const stream = new ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);\r\n                this.privStreams[audioNodeId] = stream;\r\n\r\n                try {\r\n                    this.privRecorder.record(this.privContext, this.privMediaStream, stream);\r\n                } catch (error) {\r\n                    this.onEvent(new AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));\r\n                    throw error;\r\n                }\r\n\r\n                return stream.getReader();\r\n            });\r\n    }\r\n\r\n    private onEvent = (event: AudioSourceEvent): void => {\r\n        this.privEvents.onEvent(event);\r\n        Events.instance.onEvent(event);\r\n    }\r\n\r\n    private createAudioContext = (): void => {\r\n        if (!!this.privContext) {\r\n            return;\r\n        }\r\n\r\n        // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext\r\n        const AudioContext = ((window as any).AudioContext)\r\n            || ((window as any).webkitAudioContext)\r\n            || false;\r\n\r\n        if (!AudioContext) {\r\n            throw new Error(\"Browser does not support Web Audio API (AudioContext is not available).\");\r\n        }\r\n\r\n        this.privContext = new AudioContext();\r\n    }\r\n\r\n    private destroyAudioContext = (): void => {\r\n        if (!this.privContext) {\r\n            return;\r\n        }\r\n\r\n        this.privRecorder.releaseMediaResources(this.privContext);\r\n\r\n        // This pattern brought to you by a bug in the TypeScript compiler where it\r\n        // confuses the (\"close\" in this.privContext) with this.privContext always being null as the alternate.\r\n        // https://github.com/Microsoft/TypeScript/issues/11498\r\n        let hasClose: boolean = false;\r\n        if (\"close\" in this.privContext) {\r\n            hasClose = true;\r\n        }\r\n\r\n        if (hasClose) {\r\n            this.privContext.close();\r\n            this.privContext = null;\r\n        } else if (null !== this.privContext && this.privContext.state === \"running\") {\r\n            // Suspend actually takes a callback, but analogous to the\r\n            // resume method, it'll be only fired if suspend is called\r\n            // in a direct response to a user action. The later is not always\r\n            // the case, as TurnOff is also called, when we receive an\r\n            // end-of-speech message from the service. So, doing a best effort\r\n            // fire-and-forget here.\r\n            this.privContext.suspend();\r\n        }\r\n    }\r\n}\r\n"]}